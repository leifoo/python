{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2b86e5",
   "metadata": {},
   "source": [
    "# kaggle - Intro to SQL & Advanced SQL\n",
    "\n",
    "https://www.kaggle.com/learn/intro-to-sql  (Chapter 1 -6)  \n",
    "\n",
    "https://www.kaggle.com/learn/advanced-sql  (Chapter 7-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3074beb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1. Getting Stared With SQL and BigQuery](#1.-Getting-Stared-With-SQL-and-BigQuery)\n",
    "    - [1.1 Introduction](#1.1-Introduction)\n",
    "    - [1.2 First BigQuery commands](#1.2-First-BigQuery-commands)\n",
    "    - [1.3 Table schema](#1.3-Table-schema)\n",
    "- [2. Select, From & Where](#2.-Select,-From-&-Where)\n",
    "    - [2.1 Introduction](#2.1-Introduction)\n",
    "    - [2.2 SELECT ... FROM](#2.2-SELECT-...-FROM)\n",
    "    - [2.3 WHERE ...](#2.3-WHERE-...)\n",
    "    - [2.4 Submitting the query to the dataset](#2.4-Submitting-the-query-to-the-dataset)\n",
    "- [3. Group by, Having & Count](#3.-Group-by,-Having-&-Count)\n",
    "    - [3.1 COUNT()](#3.1-COUNT())\n",
    "    - [3.2 GROUP BY](#3.2-GROUP-BY)\n",
    "    - [3.3 GROUP BY ... HAVING](#3.3-GROUP-BY-...-HAVING)\n",
    "    - [3.4 Aliasing and other improvements](#3.4-Aliasing-and-other-improvements)\n",
    "    - [3.5 Note on using GROUP BY](#3.5-Note-on-using-GROUP-BY)\n",
    "- [4. Order by](#4.-Order-by)\n",
    "    - [4.1 ORDER BY](#4.1-ORDER-BY)\n",
    "    - [4.2 Dates](#4.2-Dates)\n",
    "    - [4.3 EXTRACT](#4.3-EXTRACT)\n",
    "- [5. As & With](#5.-As-&-With)\n",
    "    - [5.1 Introduction](#5.1-Introduction)\n",
    "    - [5.2 AS](#5.2-AS)\n",
    "    - [5.3 WITH ... AS](#5.3-WITH-...-AS)\n",
    "    - [5.4 Example](#5.4-Example)\n",
    "- [6. Joining Data](#6.-Joining-Data)\n",
    "    - [6.1 Example](#6.1-Example)\n",
    "    - [6.2 JOIN](#6.2-JOIN)\n",
    "- [7. Combine information from multiple tables.](#7.-Combine-information-from-multiple-tables.)\n",
    "    - [7.1 JOINs](#7.1-JOINs)\n",
    "    - [7.2 UNIONs](#7.2-UNIONs)\n",
    "    - [7.3 Example](#7.3-Example)\n",
    "    - [7.4 Exercise](#7.4-Exercise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6fd45",
   "metadata": {},
   "source": [
    "## 1. Getting Stared With SQL and BigQuery\n",
    "\n",
    "Learn the workflow for handling big datasets with BigQuery and SQL\n",
    "\n",
    "### 1.1 Introduction\n",
    "__Structured Query Language__ (SQL), is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using __BigQuery__, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "### 1.2 First BigQuery commands\n",
    "\n",
    "Import BigQuery Python package\n",
    "> ```python\n",
    "from google.cloud import bigquery\n",
    ">```\n",
    "\n",
    "The first step in the workflow is to create a `Client` object. \n",
    "> ```python \n",
    "> # Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "> ```\n",
    "\n",
    "We'll work with a dataset of posts on [Hacker News](https://news.ycombinator.com/), a website focusing on computer science and cybersecurity news.\n",
    "\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our `hacker_news` dataset is contained in the `bigquery-public-data` project. To access the dataset,\n",
    "- We begin by constructing a reference to the dataset with the `dataset()` method.\n",
    "- Next, we use the `get_dataset()` method, along with the reference we just constructed, to fetch the dataset.\n",
    "\n",
    "> ```python\n",
    "> # Construct a reference to the \"hacker_news\" dataset\n",
    "> dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")  \n",
    ">\n",
    "> # API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "> ```\n",
    "\n",
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.  \n",
    "We use the `list_tables()` method to list the tables in the dataset.\n",
    "\n",
    "> ```python\n",
    "> # List all the tables in the \"hacker_news\" dataset\n",
    "> tables = list(client.list_tables(dataset))\n",
    "> \n",
    "> # Print names of all tables in the dataset (there are four!)\n",
    "> for table in tables:  \n",
    ">     print(table.table_id)\n",
    "> ```\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">comments\n",
    "full\n",
    "full_201510\n",
    "stories\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the `full` table in the `hacker_news` dataset.\n",
    "\n",
    "> ```python\n",
    "> # Construct a reference to the \"full\" table\n",
    "> table_ref = dataset_ref.table(\"full\")\n",
    "> \n",
    "> # API request - fetch the table\n",
    "> table = client.get_table(table_ref)\n",
    "> ```\n",
    "\n",
    "<!-- ![BigQuery](img/bigquery.png \"BigQuery\") -->\n",
    "<img src=\"img/bigquery.png\" alt=\"Drawing\" title=\"BigQuery\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd4672",
   "metadata": {},
   "source": [
    "### 1.3 Table schema\n",
    "The structure of a table is called its **schema**. We need to understand a table's schema to effectively pull out the data we want.\n",
    "\n",
    "> ```python\n",
    "> # Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "> table.schema\n",
    "> ```\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[SchemaField('title', 'STRING', 'NULLABLE', 'Story title', (), None),\n",
    " SchemaField('url', 'STRING', 'NULLABLE', 'Story url', (), None),\n",
    " ...,\n",
    " SchemaField('deleted', 'BOOLEAN', 'NULLABLE', 'Is deleted?', (), None)]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "Each `SchemaField` tells us about a specific column (which we also refer to as a field). In order, the information is:\n",
    "- **name** of the column\n",
    "- **field type** (or **datatype**) in the column\n",
    "- **mode** of the column ('NULLABLE' means that a column allows NULL values, and is the default)\n",
    "- **description** of the data in that column\n",
    "\n",
    "The first field has the SchemaField:\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "- the field (or column) is called by,\n",
    "- the data in this field is strings,\n",
    "- NULL values are allowed, and\n",
    "- it contains the usernames corresponding to each item's author.\n",
    "\n",
    "We can use the `list_rows()` method to check just the first five lines of of the full table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.) This returns a BigQuery `RowIterator` object that can quickly be converted to a pandas DataFrame with the `to_dataframe()` method.\n",
    "\n",
    "> ```python\n",
    "> # Preview the first five lines of the \"full\" table\n",
    "> client.list_rows(table, max_results=5).to_dataframe()\n",
    "> ```\n",
    "\n",
    "The list_rows() method will also let us look at just the information in a specific column. If we want to see the first five entries in the by column, for example, we can do that!\n",
    "\n",
    "> ```python\n",
    "> # Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "> client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a4e68",
   "metadata": {},
   "source": [
    "## 2. Select, From & Where\n",
    "\n",
    "The foundational components for all SQL queries\n",
    "\n",
    "### 2.1 Introduction\n",
    "\n",
    "We'll work with a small imaginary dataset `pet_records` which contains just one table, called pets.\n",
    "\n",
    "| ID | Name | Animal| \n",
    "| --- | --- | --- | \n",
    "| 1 | Dr. Harris Bonkers | Rabbit | \n",
    "| 2 | Moon | Dog|\n",
    "| 3 | Ripley | Cat |\n",
    "| 4 | Tom | Cat |\n",
    "\n",
    "### 2.2 SELECT ... FROM\n",
    "\n",
    "Select a single column\n",
    "- `SELECT` specifies the column\n",
    "- `FROM` specifies the table\n",
    "\n",
    "> ```python\n",
    "SELECT Name\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "> ```\n",
    "\n",
    "Select multiple columns\n",
    "> ```python\n",
    "SELECT Name, Animal\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "> ```\n",
    "\n",
    "Select all columns\n",
    "> ```python\n",
    "SELECT *\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "> ```\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Note:</b> when writing an SQL query, the argument we pass to FROM is not in single or double quotation marks (' or \"). It is in backticks (`).</div>\n",
    "\n",
    "### 2.3 WHERE ...\n",
    "\n",
    "Return only the rows meeting specific conditions using the `WHERE` clause.\n",
    "\n",
    "> ```python\n",
    "SELECT Name\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "WHERE Animal='Cat'\n",
    "> ```\n",
    "\n",
    "### 2.4 Submitting the query to the dataset\n",
    "\n",
    "> ```python\n",
    "query = \"\"\"\n",
    "        SELECT Name\n",
    "        FROM `bigquery-public-data.pet_records.pets`\n",
    "        WHERE Animal='Cat'\n",
    "        \"\"\"\n",
    "> # Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "> # Only run the query if it's less than 1 MB\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1000000)\n",
    "> # Set up the query (will only run if it's less than 1 MB)\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "> # API request - try to run the query, and return a pandas DataFrame\n",
    "safe_query_job.to_dataframe()\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4cd533",
   "metadata": {},
   "source": [
    "## 3. Group by, Having & Count\n",
    "\n",
    "Get more interesting insights directly from your SQL queries\n",
    "\n",
    "### 3.1 COUNT()\n",
    "\n",
    "`COUNT()` returns a count of things. If you pass it the name of a column, it will return the number of entries in that column.\n",
    "\n",
    "> ```python\n",
    "SELECT COUNT(ID)\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "> ```\n",
    "\n",
    "| f0_ |\n",
    "| --- | \n",
    "| 4 | \n",
    "\n",
    "\n",
    "`COUNT()` is an example of an **aggregate function**, which takes many values and returns one.  \n",
    "Other examples: `SUM()`, `AVG()`, `MIN()`, `MAX()`.\n",
    "\n",
    "### 3.2 GROUP BY\n",
    "\n",
    "`GROUP BY` takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like `COUNT()`.\n",
    "\n",
    "How many of each type of animal in the pets table? We can use `GROUP BY` to group together rows that have the same value in the `Animal` column, while using `COUNT()` to find out how many ID's we have in each group.\n",
    "\n",
    "> ```python\n",
    "SELECT Animal, COUNT(ID)\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "GROUP BY Animal\n",
    "> ```\n",
    "\n",
    "| Animal | f0_ |\n",
    "| ------ | --- |  \n",
    "| Rabbit | 1 |\n",
    "| Dog | 1 |\n",
    "| Cat | 2 |\n",
    "\n",
    "### 3.3 GROUP BY ... HAVING\n",
    "\n",
    "`HAVING` is used in combination with `GROUP BY` to ignore groups that don't meet certain criteria.\n",
    "\n",
    "Only include groups that have more than one ID in them\n",
    "\n",
    "> ```python\n",
    "SELECT Animal, COUNT(ID)\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "GROUP BY Animal\n",
    "HAVING COUNT(ID)>1\n",
    "> ```\n",
    "\n",
    "| Animal | f0_ |\n",
    "| ------ | --- |  \n",
    "| Cat | 2 |\n",
    "\n",
    "### 3.4 Aliasing and other improvements\n",
    "\n",
    "- Aliasing: adding `AS NewName` after you specify the aggregation replaces the column name `f0__`\n",
    "- If you are ever unsure what to put inside the `COUNT()` function, you can do `COUNT(1)` to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of your data access quota).\n",
    "\n",
    "> ```python\n",
    "SELECT Animal, COUNT(1) AS NumPets\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "GROUP BY Animal\n",
    "HAVING COUNT(1)>1\n",
    "> ```\n",
    "\n",
    "| Animal | NumPets |\n",
    "| ------ | --- |  \n",
    "| Cat | 2 |\n",
    "\n",
    "### 3.5 Note on using GROUP BY\n",
    "\n",
    "Note that because it tells SQL how to apply aggregate functions (like `COUNT()`), it doesn't make sense to use `GROUP BY` without an aggregate function. Similarly, if you have any `GROUP BY` clause, then all variables must be passed to either a\n",
    "1. `GROUP BY` command, or\n",
    "2. an aggregation function.\n",
    "\n",
    "\n",
    "> ```python\n",
    "SELECT ID, Animal, COUNT(1) AS NumPets\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "GROUP BY Animal\n",
    "HAVING COUNT(1)>1\n",
    "> ```\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:red\">SELECT list expression references column (column's name) which is neither grouped nor aggregated at\n",
    "</code>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91df936",
   "metadata": {},
   "source": [
    "## 4. Order by\n",
    "\n",
    "Order your results to focus on the most important data for your use case.\n",
    "\n",
    "### 4.1 ORDER BY\n",
    "\n",
    "`ORDER BY` is usually the <span style=\"color:blue\">**last**</span> clause in your query, and it sorts the results returned by the rest of your query.\n",
    "\n",
    "> ```python\n",
    "SELECT ID, Name, Animal\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "ORDER BY ID\n",
    "> ```\n",
    "\n",
    "| ID | Name | Animal| \n",
    "| --- | --- | --- | \n",
    "| 1 | Dr. Harris Bonkers | Rabbit | \n",
    "| 2 | Moon | Dog|\n",
    "| 3 | Ripley | Cat |\n",
    "| 4 | Tom | Cat |\n",
    "\n",
    "The `ORDER BY` clause also works for columns containing text, where the results show up in alphabetical order.\n",
    "\n",
    "> ```python\n",
    "SELECT ID, Name, Animal\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "ORDER BY Animal\n",
    "> ```\n",
    "\n",
    "| ID | Name | Animal| \n",
    "| --- | --- | --- | \n",
    "| 4 | Tom | Cat |\n",
    "| 3 | Ripley | Cat |\n",
    "| 2 | Moon | Dog|\n",
    "| 1 | Dr. Harris Bonkers | Rabbit | \n",
    "\n",
    "You can reverse the order using the `DESC` argument (default `ASC`).\n",
    "\n",
    "> ```python\n",
    "SELECT ID, Name, Animal\n",
    "FROM `bigquery-public-data.pet_records.pets`\n",
    "ORDER BY Animal DESC\n",
    "> ```\n",
    "\n",
    "| ID | Name | Animal| \n",
    "| --- | --- | --- | \n",
    "| 1 | Dr. Harris Bonkers | Rabbit | \n",
    "| 2 | Moon | Dog|\n",
    "| 3 | Ripley | Cat |\n",
    "| 4 | Tom | Cat |\n",
    "\n",
    "### 4.2 Dates\n",
    "\n",
    "There are two ways that dates can be stored in BigQuery: as a **DATE** or as a **DATETIME**.\n",
    "\n",
    "The **DATE** format has the year first, then the month, and then the day. It looks like this:  \n",
    "\n",
    "`YYYY-[M]M-[D]D`\n",
    "- YYYY: Four-digit year\n",
    "- [M]M: One or two digit month\n",
    "- [D]D: One or two digit day\n",
    "\n",
    "The **DATETIME** format is like the date format ... but with time added at the end.\n",
    "\n",
    "### 4.3 EXTRACT\n",
    "\n",
    "Often you'll want to look at part of a date, like the year or the day. You can do this with `EXTRACT`. Table `pets_with_date`.\n",
    "\n",
    "| ID | Name | Animal| Date |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | Dr. Harris Bonkers | Rabbit | 2019-04-18 | \n",
    "| 2 | Moon | Dog| 2019-05-16 |\n",
    "| 3 | Ripley | Cat | 2019-01-07 |\n",
    "| 4 | Tom | Cat | 2019-02-23 |\n",
    "\n",
    "> ```python\n",
    "SELECT Name, EXTRACT(DAY from Date) AS Day\n",
    "FROM `bigquery-public-data.pet_records.pets_with_date`\n",
    "> ```\n",
    "\n",
    "| Name | Day |\n",
    "| --- | --- |\n",
    "| Dr. Harris Bonkers | 18 | \n",
    "| Moon | 16 |\n",
    "| Ripley | 7 |\n",
    "| Tom | 23 |\n",
    "\n",
    "[Date and time functions](https://cloud.google.com/bigquery/docs/reference/legacy-sql#datetimefunctions)\n",
    "\n",
    "> ```python\n",
    "SELECT Name, EXTRACT(WEEK from Date) AS Week\n",
    "FROM `bigquery-public-data.pet_records.pets_with_date`\n",
    "> ```\n",
    "\n",
    "| Name | Week |\n",
    "| --- | --- |\n",
    "| Dr. Harris Bonkers | 15 | \n",
    "| Moon | 19 |\n",
    "| Ripley | 1 |\n",
    "| Tom | 7 |\n",
    "\n",
    "> ```python\n",
    "> # Query to find out the number of accidents for each day of the week\n",
    "query = \"\"\"\n",
    "        SELECT COUNT(consecutive_number) AS num_accidents, \n",
    "               EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n",
    "        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "        GROUP BY day_of_week\n",
    "        ORDER BY num_accidents DESC\n",
    "        \"\"\"\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f16a35",
   "metadata": {},
   "source": [
    "## 5. As & With\n",
    "\n",
    "Organize your query for better readability. This becomes especially important for complex queries.\n",
    "\n",
    "### 5.1 Introduction\n",
    "\n",
    "Use **AS** and **WITH** to tidy up queries and make them easier to read.\n",
    "\n",
    "| ID | Name | Animal| Years_old |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | Dr. Harris Bonkers | Rabbit | 4.5 | \n",
    "| 2 | Moon | Dog| 9.0 |\n",
    "| 3 | Ripley | Cat | 1.5 |\n",
    "| 4 | Tom | Cat | 7.8 |\n",
    "\n",
    "### 5.2 AS\n",
    "\n",
    "Use **AS** to rename the columns generated by your queries, which is also known as **aliasing**.\n",
    "\n",
    "### 5.3 WITH ... AS\n",
    "\n",
    "A **common table expression** (or **CTE**) is a temporary table that you return within your query. CTEs are helpful for splitting your queries into readable chunks, and you can write queries against them.\n",
    "\n",
    "For instance, you might want to use the pets table to ask questions about older animals in particular. So you can start by creating a CTE which only contains information about animals more than five years old like this:\n",
    "\n",
    "> ```python\n",
    "WITH Seniors AS\n",
    "(\n",
    "  SELECT ID, Name\n",
    "  FROM `bigquery-public-data.pet_records.pets`\n",
    "  WHERE Years_old > 5\n",
    ")\n",
    "SELECT ID\n",
    "FROM Seniors\n",
    "> ```\n",
    "\n",
    "You could do this without a CTE, but if this were the first part of a very long query, removing the CTE would make it much harder to follow.\n",
    "\n",
    "Also, it's important to note that CTEs only exist inside the query where you create them, and you can't reference them in later queries. So, any query that uses a CTE is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE.\n",
    "\n",
    "### 5.4 Example\n",
    "\n",
    "> ```python\n",
    "> # Query to select the number of transactions per date, sorted by date\n",
    "query_with_CTE = \"\"\" \n",
    "                 WITH time AS \n",
    "                 (\n",
    "                     SELECT DATE(block_timestamp) AS trans_date\n",
    "                     FROM `bigquery-public-data.crypto_bitcoin.transactions`\n",
    "                 )\n",
    "                 SELECT COUNT(1) AS transactions,\n",
    "                        trans_date\n",
    "                 FROM time\n",
    "                 GROUP BY trans_date\n",
    "                 ORDER BY trans_date\n",
    "                 \"\"\"\n",
    "> # Set up the query (cancel the query if it would use too much of \n",
    "> # your quota, with the limit set to 10 GB)\n",
    "> safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10\\*\\*10)\n",
    "query_job = client.query(query_with_CTE, job_config=safe_config)  \n",
    "> # API request - run the query, and convert the results to a pandas DataFrame\n",
    "transactions_by_date = query_job.to_dataframe()\n",
    "># Print the first five rows\n",
    "transactions_by_date.head()\n",
    "> ```\n",
    "\n",
    "> ```python\n",
    "> # plot\n",
    "transactions_by_date.set_index('trans_date').plot()\n",
    "> ```\n",
    "\n",
    "Exercise  \n",
    "Write a query that shows, for each hour of the day in the dataset, the corresponding number of trips and average speed.\n",
    "\n",
    "> ```python\n",
    "> speeds_query = \"\"\"\n",
    "               WITH RelevantRides AS\n",
    "               (\n",
    "                   SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day, \n",
    "                          trip_miles, \n",
    "                          trip_seconds\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE trip_start_timestamp > '2017-01-01' AND \n",
    "                         trip_start_timestamp < '2017-07-01' AND \n",
    "                         trip_seconds > 0 AND \n",
    "                         trip_miles > 0\n",
    "               )\n",
    "               SELECT hour_of_day, \n",
    "                      COUNT(1) AS num_trips, \n",
    "                      3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n",
    "               FROM RelevantRides\n",
    "               GROUP BY hour_of_day\n",
    "               ORDER BY hour_of_day\n",
    "               \"\"\"\n",
    "> # Set up the query (cancel the query if it would use too much of \n",
    "> # your quota)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10\\*\\* 10)\n",
    "speeds_query_job = client.query(speeds_query, job_config=safe_config)\n",
    "> # API request - run the query, and return a pandas DataFrame\n",
    "speeds_result = speeds_query_job.to_dataframe()\n",
    "> # View results\n",
    "print(speeds_result)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd99978",
   "metadata": {},
   "source": [
    "## 6. Joining Data\n",
    "\n",
    "Combine data sources. Critical for almost all real-world data problems\n",
    "\n",
    "### 6.1 Example\n",
    "\n",
    "Use **JOIN** to create a new table combining information from the pets and owners tables.\n",
    "\n",
    "`owners` table\n",
    "\n",
    "| ID | Name | Pet_ID | \n",
    "| --- | --- | --- | \n",
    "| 1 | Aubrey Little | 1 | \n",
    "| 2 | Chett Crawfish | 3 |\n",
    "| 3 | Jules Spinner | 4 |\n",
    "| 4 | Magnus | 2 |\n",
    "\n",
    "`pets` table\n",
    "\n",
    "| ID | Name | Animal| \n",
    "| --- | --- | --- | \n",
    "| 1 | Dr. Harris Bonkers | Rabbit | \n",
    "| 2 | Moon | Dog|\n",
    "| 3 | Ripley | Cat |\n",
    "| 4 | Tom | Cat |\n",
    "\n",
    "### 6.2 JOIN\n",
    "\n",
    "Using **JOIN**, we can write a query to create a table with just two columns: the name of the pet and the name of the owner.\n",
    "\n",
    "> ```python\n",
    "SELECT p.Name AS Pet_Name, o.Name AS Owner_Name,\n",
    "FROM `bigquery-public-data.pet_records.pets` AS p\n",
    "INNER JOIN `bigquery-public-data.pet_records.owners` AS o\n",
    "ON p.ID=o.Pet_ID\n",
    ">```\n",
    "\n",
    "We combine information from both tables by matching rows where the ID column in the `pets` table matches the `Pet_ID` column in the owners table.\n",
    "\n",
    "In the query, **ON** determines which column in each table to use to combine the tables. Notice that since the ID column exists in both tables, we have to clarify which one to use. We use p.ID to refer to the ID column from the pets table, and o.Pet_ID refers to the Pet_ID column from the owners table.\n",
    "\n",
    "> In general, when you're joining tables, it's a good habit to specify which table each of your columns comes from. That way, you don't have to pull up the schema every time you go back to read the query.\n",
    "\n",
    "The type of **JOIN** we're using today is called an **INNER JOIN**. That means that a row will only be put in the final output table if the value in the columns you're using to combine them shows up in both the tables you're joining.\n",
    "\n",
    "How many files are covered by each type of software license?\n",
    "<img src=\"img/join.png\" alt=\"join\" title=\"join\" style=\"width: 800px;\"/>\n",
    "\n",
    "Exercise\n",
    "\n",
    "> ```python\n",
    "from google.cloud import bigquery\n",
    "># Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "># Construct a reference to the \"stackoverflow\" dataset\n",
    "dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "># API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "> # Get a list of available tables \n",
    "tables = list(client.list_tables(dataset))\n",
    "list_of_tables = [table.table_id for table in tables] # Your code here\n",
    "> # Print your answer\n",
    "print(list_of_tables)\n",
    "> ```\n",
    "\n",
    "A **WHERE** clause can limit your results to rows with certain text using the **LIKE** feature.\n",
    "\n",
    "Use % as a \"wildcard\" for **any number of characters**. Select name contains 'ipl':\n",
    "\n",
    "> ```python\n",
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM `bigquery-public-data.pet_records.pets` \n",
    "        WHERE Name LIKE '%ipl%'\n",
    "        \"\"\"\n",
    "> ```\n",
    "\n",
    "A general function of a query that has a single row for each user who answered at least one question with a tag that includes the string \"{topic}\". Your results should have two columns:\n",
    "- `user_id` - contains the `owner_user_id` column from the `posts_answers` table\n",
    "- `number_of_answers` - contains the number of answers the user has written to \"bigquery\"-related questions\n",
    "\n",
    "> ```python\n",
    "def expert_finder(topic, client):\n",
    "    '''\n",
    "    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "    Inputs:\n",
    "        topic: A string with the topic of interest\n",
    "        client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "    Outputs:\n",
    "        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "    '''\n",
    "    my_query = \"\"\"\n",
    "               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                   ON q.id = a.parent_Id\n",
    "               WHERE q.tags like '%{topic}%'\n",
    "               GROUP BY a.owner_user_id\n",
    "               \"\"\"\n",
    "    # Set up the query (a real service would have good error handling for \n",
    "    # queries that scan too much data)\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n",
    "    my_query_job = client.query(my_query, job_config=safe_config)\n",
    "    # API request - run the query, and return a pandas DataFrame\n",
    "    results = my_query_job.to_dataframe()\n",
    "    return results\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25010a10",
   "metadata": {},
   "source": [
    "## 7. Combine information from multiple tables.\n",
    "\n",
    "Combine information from multiple tables.\n",
    "\n",
    "### 7.1 JOINs\n",
    "\n",
    "<img src=\"img/pets_owners.png\" alt=\"\" title=\"Pets and Owners tables\" style=\"width: 800px;\"/>\n",
    "\n",
    "**LEFT JOIN** returns all rows where the two tables have matching entries, along with all of the rows in the left table (whether there is a match or not).  \n",
    "**RIGHT JOIN** returns the matching rows, along with all rows in the right table (whether there is a match or not).  \n",
    "**FULL JOIN** returns all rows from both tables. Note that in general, any row that does not have a match in both tables will have NULL entries for the missing values. You can see this in the image below.\n",
    "\n",
    "<img src=\"img/jointypes.png\" alt=\"\" title=\"Different types of JOIN\" style=\"width: 800px;\"/>\n",
    "\n",
    "### 7.2 UNIONs\n",
    "\n",
    "- **JOINs** horizontally combine results from different tables. \n",
    "- **UNION** vertically concatenates columns. The example query below combines the Age columns from both tables.\n",
    "\n",
    "<img src=\"img/union.png\" alt=\"\" title=\"`UNION` combines `Age columns from both tables\" style=\"width: 800px;\"/>\n",
    "\n",
    "Note that with a **UNION**, the data types of both columns must be the same, but the column names can be different.\n",
    "\n",
    "**UNION ALL** -  include duplicate values   \n",
    "**UNION DISTINCT** drops duplicate values\n",
    "\n",
    "### 7.3 Example\n",
    "\n",
    "> ```python\n",
    "> # Query to select all stories posted on January 1, 2012, with number of comments\n",
    "join_query = \"\"\"\n",
    "             WITH c AS\n",
    "             (\n",
    "             SELECT parent, COUNT(*) as num_comments\n",
    "             FROM `bigquery-public-data.hacker_news.comments` \n",
    "             GROUP BY parent\n",
    "             )\n",
    "             SELECT s.id as story_id, s.by, s.title, c.num_comments\n",
    "             FROM `bigquery-public-data.hacker_news.stories` AS s\n",
    "             LEFT JOIN c\n",
    "             ON s.id = c.parent\n",
    "             WHERE EXTRACT(DATE FROM s.time_ts) = '2012-01-01'\n",
    "             ORDER BY c.num_comments DESC\n",
    "             \"\"\"  \n",
    "> # Run the query, and return a pandas DataFrame\n",
    "join_result = client.query(join_query).result().to_dataframe()\n",
    "join_result.head()\n",
    "> ```\n",
    "\n",
    "> ```python\n",
    "> # Query to select all users who posted stories or comments on January 1, 2014\n",
    "union_query = \"\"\"\n",
    "              SELECT c.by\n",
    "              FROM `bigquery-public-data.hacker_news.comments` AS c\n",
    "              WHERE EXTRACT(DATE FROM c.time_ts) = '2014-01-01'\n",
    "              UNION DISTINCT\n",
    "              SELECT s.by\n",
    "              FROM `bigquery-public-data.hacker_news.stories` AS s\n",
    "              WHERE EXTRACT(DATE FROM s.time_ts) = '2014-01-01'\n",
    "              \"\"\"\n",
    "> # Run the query, and return a pandas DataFrame\n",
    "union_result = client.query(union_query).result().to_dataframe()\n",
    "union_result.head()\n",
    "> ```\n",
    "\n",
    "### 7.4 Exercise\n",
    "\n",
    "1) How long does it take for questions to receive answers?\n",
    "> ```python\n",
    "correct_query = \"\"\"\n",
    "                SELECT q.id AS q_id,\n",
    "                    MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) AS time_to_answer\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                    LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                ON q.id = a.parent_id\n",
    "                WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01' \n",
    "                GROUP BY q_id\n",
    "                ORDER BY time_to_answer\n",
    "                \"\"\"\n",
    "> # Check your answer\n",
    "q_1.check()\n",
    "> # Run the query, and return a pandas DataFrame\n",
    "correct_result = client.query(correct_query).result().to_dataframe()\n",
    "print(\"Percentage of answered questions: %s%%\" % \\\n",
    "      (sum(correct_result[\"time_to_answer\"].notnull()) / len(correct_result) * 100))\n",
    "print(\"Number of questions:\", len(correct_result))\n",
    "> ```\n",
    "\n",
    "2) Initial questions and answers\n",
    "> ```python\n",
    "SELECT q.owner_user_id AS owner_user_id,\n",
    "    MIN(q.creation_date) AS q_creation_date,\n",
    "    MIN(a.creation_date) AS a_creation_date\n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "    RIGHT JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "ON q.owner_user_id = a.owner_user_id \n",
    "WHERE q.creation_date >= '2019-01-01' AND q.creation_date < '2019-02-01' \n",
    "    AND a.creation_date >= '2019-01-01' AND a.creation_date < '2019-02-01'\n",
    "GROUP BY owner_user_id\n",
    "> ```\n",
    "\n",
    "3) When did users post their first questions and answers, if ever?\n",
    "> ```python\n",
    "SELECT u.id AS id,\n",
    "    MIN(q.creation_date) AS q_creation_date,\n",
    "    MIN(a.creation_date) AS a_creation_date\n",
    "FROM `bigquery-public-data.stackoverflow.users` AS u\n",
    "    LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "        ON u.id = a.owner_user_id\n",
    "    LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "        ON u.id = q.owner_user_id\n",
    "WHERE u.creation_date >= '2019-01-01'\n",
    "    AND u.creation_date < '2019-02-01'\n",
    "GROUP BY id\n",
    "> ```\n",
    "\n",
    "\n",
    "4) How many distinct users posted on January 1, 2019? \n",
    "> ```python\n",
    "SELECT q.owner_user_id \n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "WHERE EXTRACT(DATE FROM q.creation_date) = '2019-01-01'\n",
    "UNION DISTINCT\n",
    "SELECT a.owner_user_id\n",
    "FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "WHERE EXTRACT(DATE FROM a.creation_date) = '2019-01-01'\n",
    "> ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
